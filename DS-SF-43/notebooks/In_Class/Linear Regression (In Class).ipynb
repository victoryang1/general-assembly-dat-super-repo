{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Goals</b>\n",
    "\n",
    "- Learn ins and outs of linear regression. How it fits data and makes predictions.\n",
    "- Understand key terms\n",
    "- How to interpret, improve and evaluate a linear regression model.\n",
    "- How to use it with sklearn and statsmodels libraries\n",
    "- Cross validation with linear regression\n",
    "- Work together as a class to model the King County housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression\n",
    "\n",
    "Simple linear regression is an approach for predicting a **continuous response** using a **single feature**. It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "$\\beta_0$ and $\\beta_1$ are called the **model coefficients**:\n",
    "\n",
    "- We must \"learn\" the values of these coefficients to create our model.\n",
    "- And once we've learned these coefficients, we can use the model to predict the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating (\"learning\") model coefficients\n",
    "\n",
    "- Coefficients are estimated during the model fitting process using the **least squares criterion**.\n",
    "- We are find the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estimating coefficients](images/estimating_coefficients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this diagram:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the distances between the observed values and the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Slope-intercept](images/slope_intercept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the model coefficients relate to the least squares line?\n",
    "\n",
    "- $\\beta_0$ is the **intercept** (the value of $y$ when $x$=0)\n",
    "- $\\beta_1$ is the **slope** (the change in $y$ divided by change in $x$)\n",
    "\n",
    "\n",
    "Linear Regression is highly **parametric**, meaning that is relies heavily ont he underlying shape of the data. If the data fall into a line, then lienar regression will do well. If the data does not fall in line (get it?) linear regression is likely to fail.\n",
    "\n",
    "\n",
    "Let's use linear regression to model advertising data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the observations?\n",
    "\n",
    "- Each observation represents **one market** (200 markets in the dataset)\n",
    "\n",
    "What are the features?\n",
    "\n",
    "- **TV:** advertising dollars spent on TV for a single product (in thousands of dollars)\n",
    "- **Radio:** advertising dollars spent on Radio\n",
    "- **Newspaper:** advertising dollars spent on Newspaper\n",
    "\n",
    "What is the response?\n",
    "\n",
    "- **Sales:** sales of a single product in a given market (in thousands of widgets)\n",
    "\n",
    "Questions:\n",
    "\n",
    "\n",
    "1. Is there a relationship between ads and sales?\n",
    "2. How strong is that relationship?\n",
    "3. Which ad types contribute to sales?\n",
    "4. What is the effect of each ad type of sales?\n",
    "5. Given ad spending in a particular market, can sales be predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot in Seaborn\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include a \"regression line\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize relationships between variables with pairplot\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# create a fitted model\n",
    "\n",
    "\n",
    "# print the coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['TV']\n",
    "X = \n",
    "y = \n",
    "\n",
    "# instantiate and fit\n",
    "\n",
    "# print the coefficients\n",
    "print \n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting model coefficients\n",
    "\n",
    "How do we interpret the TV coefficient ($\\beta_1$)?\n",
    "\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.0475 \"unit\" increase in Sales.\n",
    "- Meaning: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.5 widgets.\n",
    "- This is not a statement of **causation**.\n",
    "\n",
    "If an increase in TV ad spending was associated with a **decrease** in sales, $\\beta_1$ would be **negative**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model for prediction\n",
    "\n",
    "Let's say that there was a new market where the TV advertising spend was **$50,000**. What would we predict for the Sales in that market?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 7.0326 + 0.0475 \\times 50$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually calculate the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# you have to create a DataFrame since the Statsmodels formula interface expects it\n",
    "\n",
    "\n",
    "# predict for a new observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# predict for a new observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we would predict Sales of **9,409 widgets** in that market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the scale of the features matter?\n",
    "\n",
    "Let's say that TV was measured in dollars, rather than thousands of dollars. How would that affect the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TV_dollars'] = \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn to model data TV_dollars vs sales\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['TV_dollars']\n",
    "X = \n",
    "y = \n",
    "\n",
    "# instantiate and fit\n",
    "\n",
    "# print the coefficients\n",
    "print \n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for a new observation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale of the features is **irrelevant** for linear regression models, since it will only affect the scale of the coefficients, and we simply change our interpretation of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the sklearn model to graph TV versus sales and the predicted TV values vs sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing data order for plotting\n",
    "data.sort_values(\"TV\", inplace=True)\n",
    "X = data[[\"TV\"]]\n",
    "y = data.sales\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "preds = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions by passing X into model\n",
    "\n",
    "\n",
    "#Set plot size to (12,8)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "#Make scatter of X and y\n",
    "plt.scatter(X.values,y, s = 50)\n",
    "#Make line plot of X and preds\n",
    "plt.plot(X.values, preds, \"r\", linewidth= 7, alpha = .6)\n",
    "\n",
    "plt.xlabel(\"TV ad dollars\")\n",
    "plt.ylabel(\"Sales\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residuals after fitting a linear model\n",
    "plt.figure(figsize=(11, 9))\n",
    "sns.residplot(X.values, y, color=\"g\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and variance\n",
    "\n",
    "Linear regression is a low variance/high bias model:\n",
    "\n",
    "- **Low variance:** Under repeated sampling from the underlying population, the line will stay roughly in the same place\n",
    "- **High bias:** The line will rarely fit the data well\n",
    "\n",
    "A closely related concept is **confidence intervals**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "\n",
    "Statsmodels calculates 95% confidence intervals for our model coefficients, which are interpreted as follows: If the population from which this sample was drawn was **sampled 100 times**, approximately **95 of those confidence intervals** would contain the \"true\" coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# print the confidence intervals for the model coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We only have a **single sample of data**, and not the **entire population of data**.\n",
    "- The \"true\" coefficient is either within this interval or it isn't, but there's no way to actually know.\n",
    "- We estimate the coefficient with the data we do have, and we show uncertainty about that estimate by giving a range that the coefficient is **probably** within.\n",
    "- From Quora: [What is a confidence interval in layman's terms?](http://www.quora.com/What-is-a-confidence-interval-in-laymans-terms/answer/Michael-Hochster)\n",
    "\n",
    "Note: 95% confidence intervals are just a convention. You can create 90% confidence intervals (which will be more narrow), 99% confidence intervals (which will be wider), or whatever intervals you like.\n",
    "\n",
    "A closely related concept is **hypothesis testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model coefficients, here is the conventional hypothesis test:\n",
    "\n",
    "- **null hypothesis:** There is no relationship between TV ads and Sales (and thus $\\beta_1$ equals zero)\n",
    "- **alternative hypothesis:** There is a relationship between TV ads and Sales (and thus $\\beta_1$ is not equal to zero)\n",
    "\n",
    "How do we test this hypothesis?\n",
    "\n",
    "- The **p-value** is the probability that the relationship we are observing is occurring purely by chance.\n",
    "- If the 95% confidence interval for a coefficient **does not include zero**, the p-value will be **less than 0.05**, and we will reject the null (and thus believe the alternative).\n",
    "- If the 95% confidence interval **includes zero**, the p-value will be **greater than 0.05**, and we will fail to reject the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show summary table of stats models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the p-values for the model coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, a p-value less than 0.05 is one way to decide whether there is **likely** a relationship between the feature and the response. In this case, the p-value for TV is far less than 0.05, and so we **believe** that there is a relationship between TV ads and Sales.\n",
    "\n",
    "Note that we generally ignore the p-value for the intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does the model fit the data?\n",
    "\n",
    "R-squared:\n",
    "\n",
    "- A common way to evaluate the overall fit of a linear model\n",
    "- Defined as the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model\n",
    "- Also defined as the reduction in error over the **null model**, which is the model that simply predicts the mean of the observed response\n",
    "- Between 0 and 1, and higher is better\n",
    "\n",
    "![q](https://i.stack.imgur.com/xb1VY.png)\n",
    "\n",
    "![s](https://i.stack.imgur.com/8OMsa.png)\n",
    "\n",
    "\n",
    "Here's an example of what R-squared \"looks like\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 basically measures how well a model does versus the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R-squared](images/r_squared.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stats models\n",
    "# print the R-squared value for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn\n",
    "#Method number one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method number two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The threshold for a **\"good\" R-squared value** is highly dependent on the particular domain.\n",
    "- R-squared is more useful as a tool for **comparing models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features, which is called **multiple linear regression**:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCIKIT-LEARN ###\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "X = \n",
    "y = \n",
    "\n",
    "# instantiate and fit\n",
    "linreg = \n",
    "\n",
    "\n",
    "# print the coefficients\n",
    "print \n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATSMODELS ###\n",
    "\n",
    "# create a fitted model with all three features\n",
    "lm = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given amount of Radio and Newspaper spending, an increase of $1000 in **TV** spending is associated with an **increase in Sales of 45.8 widgets**.\n",
    "\n",
    "For a given amount of TV and Newspaper spending, an increase of $1000 in **Radio** spending is associated with an **increase in Sales of 188.5 widgets**.\n",
    "\n",
    "For a given amount of TV and Radio spending, an increase of $1000 in **Newspaper** spending is associated with an **decrease in Sales of 1.0 widgets**. How could that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "How do I decide **which features to include** in a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Using p-values\n",
    "\n",
    "We could try a model with all features, and only keep features in the model if they have **small p-values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### STATSMODELS ###\n",
    "\n",
    "# create a fitted model with all three features\n",
    "lm = \n",
    "\n",
    "# print the p-values for the model coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates we would reject the null hypothesis for **TV and Radio** (that there is no association between those features and Sales), and fail to reject the null hypothesis for **Newspaper**. Thus, we would keep TV and Radio in the model.\n",
    "\n",
    "However, this approach has **drawbacks**:\n",
    "\n",
    "- Linear models rely upon a lot of **assumptions** (such as the features being independent), and if those assumptions are violated (which they usually are), p-values are less reliable.\n",
    "- Using a p-value cutoff of 0.05 means that if you add 100 features to a model that are **pure noise**, 5 of them (on average) will still be counted as significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using R-squared\n",
    "\n",
    "We could try models with different sets of features, and **compare their R-squared values**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared value for the model with two features\n",
    "lm = smf.ols(formula='sales ~ TV + radio', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared value for the model with three features\n",
    "lm = smf.ols(formula='sales ~ TV + radio + newspaper', data=data).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would seem to indicate that the best model includes **all three features**. Is that right?\n",
    "\n",
    "- R-squared will always increase as you add more features to the model, even if they are **unrelated** to the response.\n",
    "- As such, using R-squared as a model evaluation metric can lead to **overfitting**.\n",
    "- **Adjusted R-squared** is an alternative that penalizes model complexity (to control for overfitting), but it generally [under-penalizes complexity](http://scott.fortmann-roe.com/docs/MeasuringError.html).\n",
    "\n",
    "As well, R-squared depends on the same assumptions as p-values, and it's less reliable if those assumptions are violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split, cross validation, and evaluation metrics\n",
    "\n",
    "A better approach to feature selection!\n",
    "\n",
    "- They attempt to directly estimate how well your model will **generalize** to out-of-sample data.\n",
    "- They rely on **fewer assumptions** that linear regression.\n",
    "- They can easily be applied to **any model**, not just linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics for regression problems\n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. We need evaluation metrics designed for comparing **continuous values**.\n",
    "\n",
    "Let's create some example numeric predictions, and calculate three common evaluation metrics for regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define true and predicted response values\n",
    "y_true = [100, 50, 30, 20]\n",
    "y_pred = [90, 50, 50, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MAE using sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate MSE using sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate RMSE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these metrics:\n",
    "\n",
    "- **MAE** is the easiest to understand, because it's the average error.\n",
    "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are **loss functions**, because we want to minimize them.\n",
    "\n",
    "Here's an additional example, to demonstrate how MSE/RMSE punish larger errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same true values as above\n",
    "y_true = [100, 50, 30, 20]\n",
    "\n",
    "# new set of predicted values\n",
    "y_pred = [60, 50, 30, 20]\n",
    "\n",
    "# MAE is the same as before\n",
    "print (metrics.mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "# RMSE is larger than before\n",
    "print (np.sqrt(metrics.mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using train/test split for feature selection\n",
    "\n",
    "Let's use train/test split with RMSE to decide whether Newspaper should be kept in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re import data\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
    "data.head()\n",
    "\n",
    "X = data.drop(\"sales\", axis = 1)\n",
    "y = data.sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make train test split\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model on training data and apply it on both training and testing data\n",
    "\n",
    "#Intialize model\n",
    "lr = \n",
    "\n",
    "\n",
    "#Test model on training data\n",
    "train_score = \n",
    "print (\"Training R2 score is {}\".format(train_score))\n",
    "#Test model on testing data\n",
    "test_score = \n",
    "print (\"Testing R2 score is {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this tell us? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts X and y and computes testing RMSE\n",
    "def cross_val_rmse(X, y):\n",
    "    linreg = LinearRegression()\n",
    "    scores = cross_val_score(linreg, X, y, cv=5, scoring='mean_squared_error')\n",
    "    return np.sqrt(abs(scores)).mean() # return average RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include Newspaper\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "X = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Newspaper \n",
    "feature_cols = ['TV', 'radio']\n",
    "X = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only TV\n",
    "feature_cols = ['TV']\n",
    "X = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this process again change scoring metrics to R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make cross val function with R2\n",
    "# include Newspaper\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make cross val function with R2\n",
    "# Exclude Newspaper\n",
    "feature_cols = ['TV', 'radio']\n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make cross val function with R2\n",
    "# Only TV\n",
    "feature_cols = ['TV']\n",
    "X = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these results tell us? Which metric do you prefer? The R2 or RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in\n",
    "df = pd.read_pickle(\"../../data/survey_data.pkl\")\n",
    "# Take a look at the datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the correlations\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation and Multicollinearity\n",
    "We notice that some of the variables are highly correlated.  This is something we might want to take into consideration later.  When 2 predictor variables are highly correlated this is called [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity) and it is something we want to watch out for as it can destabilize our model.  In the extreme case, when 2 predictors are perfectly correlated then there is absolutely nothing gained by making both variables part of our regression.\n",
    "\n",
    "The other takeaway from this table is that some of our predictors are highly correlated with our ***target variable Y***.  This is a good thing, it means that these are the variables that we most likely want to include as part of our model as they explain a large amount of the variance in the target variable (correlation=R, variance_explained=R<sup>2</sup>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all of the variable-to-variable relations as scatterplots\n",
    "sns.pairplot(df, size = 1.2, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's model this data using linear regresion in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize an empty model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Assign X and y\n",
    "X = df.drop(\"Y\", axis = 1)\n",
    "# Choose the response variable(s)\n",
    "y = df.Y\n",
    "# Fit the model to the full dataset\n",
    "lr.fit(X, y)\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this again but only X1, X3, X4, the three most correlated variables with Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize an empty model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Assign X and y\n",
    "X = df[[\"X1\", \"X3\", \"X4\"]]\n",
    "# Choose the response variable(s)\n",
    "y = df.Y\n",
    "# Fit the model to the full dataset\n",
    "lr.fit(X, y)\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What effect did this have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play around with the data and try to find the best combinations of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain\n",
    "- Highly interpretable\n",
    "- Model training and prediction are fast\n",
    "- No tuning is required (excluding regularization)\n",
    "- Features don't need scaling\n",
    "- Can perform well with a small number of observations\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias\n",
    "- Sensitive to irrelevant features (scaling won't help but feature selection will)\n",
    "- Makes improper predictions (lines are not bound on any side)\n",
    "- Can't automatically learn feature interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9\n",
    "- http://www-bcf.usc.edu/~gareth/ISL/\n",
    "- http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/\n",
    "- http://www.dataschool.io/applying-and-interpreting-linear-regression/\n",
    "- https://www.datarobot.com/blog/ordinary-least-squares-in-python/\n",
    "- https://www.datarobot.com/blog/multiple-regression-using-statsmodels/\n",
    "- https://medium.com/@GalarnykMichael/linear-regression-using-python-b29174c3797a#.vczf85s0s\n",
    "- https://www.youtube.com/watch?v=5-QY6MCt7fo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Class Exercise\n",
    "\n",
    "I want you to work with your table partner to model housing prices using the king county home sales. Start simple by choosing 3-5 features, see how well you can do with that and then add a couple more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data\n",
    "\n",
    "pd.set_option(\"max.columns\", 30)\n",
    "kc = pd.read_csv(\"../../data/kc_house_data.csv\")\n",
    "kc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
